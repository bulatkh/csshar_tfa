experiment:
  seed: 28
  num_epochs_ssl: 200
  num_epochs_fine_tuning: 100
  batch_size_fine_tuning: 128

model:
  transformer:
    from_module: transformer
    encoder_class_name: Transformer
    encoder_name: transformer
    args: []
    kwargs:
      in_channels: 6
      max_len: 30

      kernel_size: 3
      out_channels: [64, 128, 256]
      
      num_head: 8
      num_layers: 6

      lr: 0.0001
      optimizer_name: "adam"
  ssl:
      args: []
      kwargs:
        ssl_lr: 0.0001
        projection_hidden: 512
        embedding_size: 256

        sim_coeff: 10
        std_coeff: 10
        cov_coeff: 5

        ssl_batch_size: 256
        optimizer_name_ssl: "lars"